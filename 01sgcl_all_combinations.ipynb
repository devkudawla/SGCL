{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install dill\n",
        "!pip install dotmap\n",
        "!pip install  dgl -f https://data.dgl.ai/wheels/cu117/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNzd43W7KGlF",
        "outputId": "3762c516-3a65-4943-b3f5-887c864c8468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill\n",
            "Successfully installed dill-0.4.0\n",
            "Collecting dotmap\n",
            "  Downloading dotmap-1.3.30-py3-none-any.whl.metadata (3.2 kB)\n",
            "Downloading dotmap-1.3.30-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: dotmap\n",
            "Successfully installed dotmap-1.3.30\n",
            "Looking in links: https://data.dgl.ai/wheels/cu117/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/cu117/dgl-2.1.0%2Bcu117-cp311-cp311-manylinux1_x86_64.whl (257.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.4/257.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.15.2)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl) (4.67.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (5.9.5)\n",
            "Collecting torchdata>=0.5.0 (from dgl)\n",
            "  Downloading torchdata-0.11.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2025.4.26)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from torchdata>=0.5.0->dgl) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2->torchdata>=0.5.0->dgl)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (3.0.2)\n",
            "Downloading torchdata-0.11.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchdata, dgl\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed dgl-2.1.0+cu117 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchdata-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeZ39KEnKVo2",
        "outputId": "4e6e7b32-a910-4217-b640-7b8464d7afc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y dgl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-khrU46Lwv-",
        "outputId": "8d8a612c-0238-47ae-d84f-2ef7fa00a0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: dgl 2.1.0+cu117\n",
            "Uninstalling dgl-2.1.0+cu117:\n",
            "  Successfully uninstalled dgl-2.1.0+cu117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl==1.1.2 -f https://data.dgl.ai/wheels/repo.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j8GFRP0Lz_q",
        "outputId": "f6bc3562-036a-4490-846b-cb7677d8b1be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl==1.1.2\n",
            "  Downloading dgl-1.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (530 bytes)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (1.15.2)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (4.67.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl==1.1.2) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.1.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.1.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.1.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl==1.1.2) (2025.4.26)\n",
            "Downloading dgl-1.1.2-cp311-cp311-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dgl\n",
            "Successfully installed dgl-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Basic libraries ===\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "# === PyTorch ===\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# === DGL for graph operations ===\n",
        "import dgl\n",
        "from dgl.nn import GraphConv\n",
        "\n",
        "# === ML Evaluation ===\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
        "\n",
        "# === Misc ===\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# === Set random seeds for reproducibility ===\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "# === Device setup ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27No44tuLiLj",
        "outputId": "25518371-a3f9-4621-b130-12fc873fcc0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Load edge data\n",
        "label_df = pd.read_csv(\"/content/drive/MyDrive/bitcoin_alpha/label_train.csv\")\n",
        "\n",
        "# Get total number of nodes (assuming 0-based IDs)\n",
        "num_nodes = int(max(label_df['src'].max(), label_df['dst'].max()) + 1)\n",
        "\n",
        "# Generate random features for each node (64-dim)\n",
        "features = torch.randn((num_nodes, 64), dtype=torch.float32)\n",
        "\n",
        "# Store features and node count in dicts for DGL\n",
        "node_features = {'user': features}\n",
        "num_nodes_dict = {'user': num_nodes}\n",
        "\n",
        "print(\"✅ User features loaded. Shape:\", features.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ-oxq8wMtxt",
        "outputId": "1c830360-ef7d-4f9b-c599-fe70f12cf4b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ User features loaded. Shape: torch.Size([3783, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dgl\n",
        "\n",
        "# Separate edges by sign\n",
        "pos_edges = label_df[label_df['label'] == 1]\n",
        "neg_edges = label_df[label_df['label'] == 0]\n",
        "\n",
        "# Create edge index arrays\n",
        "src_pos = torch.tensor(pos_edges['src'].values, dtype=torch.int64)\n",
        "dst_pos = torch.tensor(pos_edges['dst'].values, dtype=torch.int64)\n",
        "src_neg = torch.tensor(neg_edges['src'].values, dtype=torch.int64)\n",
        "dst_neg = torch.tensor(neg_edges['dst'].values, dtype=torch.int64)\n",
        "\n",
        "# Build heterograph with signed edge types\n",
        "graph_data = {\n",
        "    ('user', 'positive', 'user'): (src_pos, dst_pos),\n",
        "    ('user', 'negative', 'user'): (src_neg, dst_neg)\n",
        "}\n",
        "\n",
        "graph = dgl.heterograph(graph_data, num_nodes_dict=num_nodes_dict)\n",
        "\n",
        "# Assign features to graph\n",
        "graph.nodes['user'].data['feature'] = node_features['user']\n",
        "\n",
        "print(\"✅ Graph loaded with:\")\n",
        "print(\"  Nodes:\", graph.num_nodes('user'))\n",
        "print(\"  Positive edges:\", graph.num_edges(('user', 'positive', 'user')))\n",
        "print(\"  Negative edges:\", graph.num_edges(('user', 'negative', 'user')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwWGJI8sMzu-",
        "outputId": "a4fa3d96-41b5-4612-ef40-1b1d4479acd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Graph loaded with:\n",
            "  Nodes: 3783\n",
            "  Positive edges: 22650\n",
            "  Negative edges: 1536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class LabelPairs(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.u = torch.tensor(df['src'].values, dtype=torch.long)\n",
        "        self.v = torch.tensor(df['dst'].values, dtype=torch.long)\n",
        "        self.labels = torch.tensor(df['label'].values, dtype=torch.float32)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (self.u[index], self.v[index]), self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Initialize dataset\n",
        "label_dataset = LabelPairs(label_df)\n",
        "print(\"✅ Label dataset ready. Total pairs:\", len(label_dataset))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNXdAoodM8ex",
        "outputId": "865133c3-71d9-461f-929d-d1772b8ec7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Label dataset ready. Total pairs: 24186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "def get_unstable_edges_from_balance_theory(dgl_graph):\n",
        "    \"\"\"\n",
        "    Returns a set of edges (u, v) that are part of at least one unbalanced triad,\n",
        "    based on balance theory: a triad is unbalanced if the product of its edge signs is negative.\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 1: Convert to undirected signed graph ===\n",
        "    G = nx.Graph()\n",
        "\n",
        "    for canonical_etype in dgl_graph.canonical_etypes:\n",
        "        src, dst = dgl_graph.edges(etype=canonical_etype)\n",
        "        sign = +1 if 'positive' in canonical_etype else -1\n",
        "\n",
        "        # Treat graph as undirected: add both (u,v) and (v,u) to normalize\n",
        "        for u, v in zip(src.tolist(), dst.tolist()):\n",
        "            if u == v:\n",
        "                continue\n",
        "            a, b = min(u, v), max(u, v)  # consistent undirected edge\n",
        "            G.add_edge(a, b, sign=sign)\n",
        "\n",
        "    # === Step 2: Triangle enumeration ===\n",
        "    unstable_edges = set()\n",
        "\n",
        "    for triangle in nx.enumerate_all_cliques(G):\n",
        "        if len(triangle) != 3:\n",
        "            continue\n",
        "        u, v, w = triangle\n",
        "\n",
        "        # Get signs of each edge\n",
        "        s_uv = G[u][v]['sign']\n",
        "        s_vw = G[v][w]['sign']\n",
        "        s_wu = G[w][u]['sign']\n",
        "\n",
        "        sign_product = s_uv * s_vw * s_wu\n",
        "\n",
        "        # If unbalanced (i.e., negative product), mark all edges\n",
        "        if sign_product < 0:\n",
        "            unstable_edges.add(tuple(sorted((u, v))))\n",
        "            unstable_edges.add(tuple(sorted((v, w))))\n",
        "            unstable_edges.add(tuple(sorted((w, u))))\n",
        "\n",
        "    print(f\"✅ Found {len(unstable_edges)} unstable edges based on balance theory.\")\n",
        "    return unstable_edges\n"
      ],
      "metadata": {
        "id": "wmM0-etEGdJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unstable_edges = get_unstable_edges_from_balance_theory(graph)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSuvD5iZHDVs",
        "outputId": "a0199466-277b-40fa-e50e-f0c46af83623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Found 3230 unstable edges based on balance theory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl\n",
        "from dgl.nn import GraphConv\n",
        "\n",
        "# === GCN encoder with 2 layers ===\n",
        "class GCNEncoder(nn.Module):\n",
        "    def __init__(self, in_feats, hidden_feats, out_feats):\n",
        "        super().__init__()\n",
        "        self.conv1 = GraphConv(in_feats, hidden_feats, activation=F.relu)\n",
        "        self.conv2 = GraphConv(hidden_feats, out_feats)\n",
        "\n",
        "    def forward(self, g, nids):\n",
        "        h = g.ndata['feature']\n",
        "        h = self.conv1(g, h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h[nids]\n",
        "\n",
        "# === SGCL Model: encoder + MLP + loss functions ===\n",
        "class SGCLModel(nn.Module):\n",
        "    def __init__(self, in_dim=64, hidden_dim=128, out_dim=64):\n",
        "        super().__init__()\n",
        "        self.encoder = GCNEncoder(in_dim, hidden_dim, out_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(out_dim * 2, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def get_embeddings(self, g, nids):\n",
        "      if 'feature' not in g.ndata:\n",
        "         raise KeyError(\"Input graph is missing node features before homogenization.\")\n",
        "\n",
        "    # Convert to homogeneous and keep features\n",
        "      g = dgl.to_homogeneous(g, ndata=['feature'])\n",
        "\n",
        "      # ✅ Add self-loops to fix zero in-degree problem\n",
        "      g = dgl.add_self_loop(g)\n",
        "\n",
        "      return self.encoder(g, nids)\n",
        "\n",
        "\n",
        "    # Convert to homogeneous graph and preserve features\n",
        "      g = dgl.to_homogeneous(g, ndata=['feature'])\n",
        "\n",
        "      return self.encoder(g, nids)\n",
        "\n",
        "\n",
        "    def compute_contrastive_loss(self, z1, z2):\n",
        "        z1 = F.normalize(z1, dim=1)\n",
        "        z2 = F.normalize(z2, dim=1)\n",
        "        return 2 - 2 * (z1 * z2).sum(dim=1).mean()\n",
        "\n",
        "    def predict(self, z, u, v):\n",
        "        h_u = z[u]\n",
        "        h_v = z[v]\n",
        "        h = torch.cat([h_u, h_v], dim=1)\n",
        "        return self.mlp(h).squeeze()\n",
        "\n",
        "    def compute_label_loss(self, scores, labels):\n",
        "        return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "# === Augmentation: feature masking ===\n",
        "def generate_attr_graph(g, mask_ratio=0.3):\n",
        "    g_attr = g.clone()\n",
        "    if 'feature' not in g_attr.ndata:\n",
        "        raise KeyError(\"Original graph is missing 'feature' in node data.\")\n",
        "\n",
        "    feature = g_attr.ndata['feature']\n",
        "    noise = torch.randn_like(feature)\n",
        "    mask = (torch.rand_like(feature) > mask_ratio).float()\n",
        "    noisy_feature = feature * mask + noise * (1 - mask)\n",
        "\n",
        "    g_attr.ndata['feature'] = noisy_feature\n",
        "    return g_attr\n",
        "\n",
        "# === Augmentation: structure perturbation ===\n",
        "def generate_stru_graph(g, drop_ratio=0.2):\n",
        "    new_data = {}\n",
        "\n",
        "    for canonical_etype in g.canonical_etypes:\n",
        "        src, dst = g.edges(etype=canonical_etype)\n",
        "        num_edges = len(src)\n",
        "        num_drop = int(num_edges * drop_ratio)\n",
        "\n",
        "        # Drop a random portion\n",
        "        perm = torch.randperm(num_edges)\n",
        "        keep = perm[num_drop:]\n",
        "        src_keep = src[keep]\n",
        "        dst_keep = dst[keep]\n",
        "\n",
        "        # Add new random edges\n",
        "        new_src = torch.randint(0, g.num_nodes('user'), (num_drop,))\n",
        "        new_dst = torch.randint(0, g.num_nodes('user'), (num_drop,))\n",
        "\n",
        "        final_src = torch.cat([src_keep, new_src])\n",
        "        final_dst = torch.cat([dst_keep, new_dst])\n",
        "        new_data[canonical_etype] = (final_src, final_dst)\n",
        "\n",
        "    g_stru = dgl.heterograph(new_data, num_nodes_dict={'user': g.num_nodes('user')})\n",
        "\n",
        "    # Copy features from original graph\n",
        "    if 'feature' in g.ndata:\n",
        "        g_stru.ndata['feature'] = g.ndata['feature']\n",
        "    else:\n",
        "        raise KeyError(\"Original graph is missing 'feature' in node data.\")\n",
        "\n",
        "    return g_stru\n",
        "#sign perturbation\n",
        "def generate_sign_flip_graph(g, flip_ratio=0.2):\n",
        "    import copy\n",
        "    import random\n",
        "\n",
        "    g_flipped = copy.deepcopy(g)\n",
        "    new_data = {}\n",
        "\n",
        "    for canonical_etype in g.canonical_etypes:\n",
        "        src, dst = g.edges(etype=canonical_etype)\n",
        "        num_edges = len(src)\n",
        "        num_flip = int(flip_ratio * num_edges)\n",
        "\n",
        "        # Randomly select edges to flip\n",
        "        perm = torch.randperm(num_edges)\n",
        "        flip_idx = perm[:num_flip]\n",
        "        keep_idx = perm[num_flip:]\n",
        "\n",
        "        src_keep = src[keep_idx]\n",
        "        dst_keep = dst[keep_idx]\n",
        "\n",
        "        # Determine new flipped type\n",
        "        if 'positive' in canonical_etype:\n",
        "            flipped_type = ('user', 'negative', 'user')\n",
        "        elif 'negative' in canonical_etype:\n",
        "            flipped_type = ('user', 'positive', 'user')\n",
        "        else:\n",
        "            flipped_type = canonical_etype  # fallback (no flip)\n",
        "\n",
        "        # Keep edges in their original type\n",
        "        if canonical_etype not in new_data:\n",
        "            new_data[canonical_etype] = (src_keep, dst_keep)\n",
        "        else:\n",
        "            new_data[canonical_etype] = (\n",
        "                torch.cat([new_data[canonical_etype][0], src_keep]),\n",
        "                torch.cat([new_data[canonical_etype][1], dst_keep])\n",
        "            )\n",
        "\n",
        "        # Add flipped edges under new type\n",
        "        if flipped_type not in new_data:\n",
        "            new_data[flipped_type] = (src[flip_idx], dst[flip_idx])\n",
        "        else:\n",
        "            new_data[flipped_type] = (\n",
        "                torch.cat([new_data[flipped_type][0], src[flip_idx]]),\n",
        "                torch.cat([new_data[flipped_type][1], dst[flip_idx]])\n",
        "            )\n",
        "\n",
        "    # Reconstruct heterograph\n",
        "    g_flipped = dgl.heterograph(new_data, num_nodes_dict={'user': g.num_nodes('user')})\n",
        "    g_flipped.ndata['feature'] = g.ndata['feature']\n",
        "\n",
        "    return g_flipped\n",
        "\n",
        "#using the balance theory\n",
        "\n",
        "def generate_balance_theory_augmented_graph(g, unstable_edges, flip_prob=0.5):\n",
        "    \"\"\"\n",
        "    Flips the sign of edges (u, v) that are part of unbalanced triads with probability flip_prob.\n",
        "    \"\"\"\n",
        "    import copy\n",
        "    import random\n",
        "\n",
        "    new_data = {}\n",
        "\n",
        "    # Loop through each edge type (positive, negative)\n",
        "    for canonical_etype in g.canonical_etypes:\n",
        "        src, dst = g.edges(etype=canonical_etype)\n",
        "        sign = 'positive' if 'positive' in canonical_etype else 'negative'\n",
        "        new_type = ('user', 'positive', 'user') if sign == 'negative' else ('user', 'negative', 'user')\n",
        "\n",
        "        keep_src, keep_dst = [], []\n",
        "        flip_src, flip_dst = [], []\n",
        "\n",
        "        for u, v in zip(src.tolist(), dst.tolist()):\n",
        "            a, b = min(u, v), max(u, v)  # undirected comparison\n",
        "\n",
        "            if (a, b) in unstable_edges and random.random() < flip_prob:\n",
        "                # Flip this edge to the opposite sign\n",
        "                flip_src.append(u)\n",
        "                flip_dst.append(v)\n",
        "            else:\n",
        "                # Keep edge in original sign\n",
        "                keep_src.append(u)\n",
        "                keep_dst.append(v)\n",
        "\n",
        "        # Add unflipped edges to original type\n",
        "        if canonical_etype not in new_data:\n",
        "            new_data[canonical_etype] = (torch.tensor(keep_src), torch.tensor(keep_dst))\n",
        "        else:\n",
        "            new_data[canonical_etype] = (\n",
        "                torch.cat([new_data[canonical_etype][0], torch.tensor(keep_src)]),\n",
        "                torch.cat([new_data[canonical_etype][1], torch.tensor(keep_dst)])\n",
        "            )\n",
        "\n",
        "        # Add flipped edges to new (opposite sign) type\n",
        "        if flip_src:\n",
        "            if new_type not in new_data:\n",
        "                new_data[new_type] = (torch.tensor(flip_src), torch.tensor(flip_dst))\n",
        "            else:\n",
        "                new_data[new_type] = (\n",
        "                    torch.cat([new_data[new_type][0], torch.tensor(flip_src)]),\n",
        "                    torch.cat([new_data[new_type][1], torch.tensor(flip_dst)])\n",
        "                )\n",
        "\n",
        "    # Rebuild the graph\n",
        "    g_new = dgl.heterograph(new_data, num_nodes_dict={'user': g.num_nodes('user')})\n",
        "    g_new.ndata['feature'] = g.ndata['feature']\n",
        "\n",
        "    # print(f\"✅ Graph augmented with balance-theory sign flipping.\")\n",
        "    return g_new\n",
        "\n",
        "\n",
        "\n",
        "# === Wrapper to generate both augmentations ===\n",
        "def augment_graph(g):\n",
        "    # a = generate_attr_graph(g, mask_ratio=0.3)\n",
        "    # a = generate_sign_flip_graph(graph, flip_ratio=0.3)\n",
        "    a = generate_stru_graph(g, drop_ratio=0.3)\n",
        "\n",
        "    b = generate_balance_theory_augmented_graph(graph, unstable_edges, flip_prob=0.3)\n",
        "\n",
        "    return a,b\n"
      ],
      "metadata": {
        "id": "wQgSeVj3uzJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kORmB02wGbro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === Hyperparameters ===\n",
        "in_dim = 64         # feature dim\n",
        "hidden_dim = 128    # hidden layer in GCN\n",
        "out_dim = 64        # final embedding dim\n",
        "batch_size = 256\n",
        "epochs = 20        # you can increase later\n",
        "alpha = 0.5         # weight for contrastive loss\n",
        "lr = 1e-3\n",
        "\n",
        "# === Initialize model, optimizer ===\n",
        "model = SGCLModel(in_dim, hidden_dim, out_dim).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# === DataLoader for label pairs ===\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(label_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(\"✅ Model and DataLoader ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As21Gmxnvjz6",
        "outputId": "f2dc5149-c31a-4d0b-96b8-48fca68a7657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and DataLoader ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (pair, label) in train_loader:\n",
        "        u, v = pair\n",
        "        u = u.to(device)\n",
        "        v = v.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        # === Augment graph\n",
        "        g_attr, g_stru = augment_graph(graph)\n",
        "\n",
        "        # === Move to device\n",
        "        g_attr = g_attr.to(device)\n",
        "        g_stru = g_stru.to(device)\n",
        "\n",
        "        # === Node IDs involved\n",
        "        nids = torch.unique(torch.cat([u, v]))\n",
        "\n",
        "        # === Get embeddings from both views\n",
        "        z1 = model.get_embeddings(g_attr, nids)\n",
        "        z2 = model.get_embeddings(g_stru, nids)\n",
        "\n",
        "        # === Contrastive loss between views\n",
        "        loss_cl = model.compute_contrastive_loss(z1, z2)\n",
        "\n",
        "        # === Link prediction logits\n",
        "        z_all = model.get_embeddings(graph.to(device), nids)\n",
        "              # === Map global u/v to local indices in z\n",
        "        nid_map = {nid.item(): i for i, nid in enumerate(nids)}\n",
        "        u_local = torch.tensor([nid_map[int(x)] for x in u.tolist()], device=device)\n",
        "        v_local = torch.tensor([nid_map[int(x)] for x in v.tolist()], device=device)\n",
        "\n",
        "# === Predict using local indices\n",
        "        scores = model.predict(z_all, u_local, v_local)\n",
        "\n",
        "        loss_pred = model.compute_label_loss(scores, label)\n",
        "\n",
        "        # === Joint loss\n",
        "        loss = loss_pred + alpha * loss_cl\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_YATl_awEgz",
        "outputId": "add93699-4c9d-44fd-856a-a7b023e77306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Loss: 31.1148\n",
            "Epoch 2/20 | Loss: 24.3636\n",
            "Epoch 3/20 | Loss: 23.2418\n",
            "Epoch 4/20 | Loss: 21.9858\n",
            "Epoch 5/20 | Loss: 19.8112\n",
            "Epoch 6/20 | Loss: 18.7219\n",
            "Epoch 7/20 | Loss: 17.4291\n",
            "Epoch 8/20 | Loss: 16.3470\n",
            "Epoch 9/20 | Loss: 15.6584\n",
            "Epoch 10/20 | Loss: 15.0984\n",
            "Epoch 11/20 | Loss: 14.6209\n",
            "Epoch 12/20 | Loss: 14.0638\n",
            "Epoch 13/20 | Loss: 13.6804\n",
            "Epoch 14/20 | Loss: 13.3383\n",
            "Epoch 15/20 | Loss: 13.0944\n",
            "Epoch 16/20 | Loss: 12.7786\n",
            "Epoch 17/20 | Loss: 12.4967\n",
            "Epoch 18/20 | Loss: 12.2543\n",
            "Epoch 19/20 | Loss: 12.2871\n",
            "Epoch 20/20 | Loss: 12.0811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import (\n",
        "    roc_auc_score, f1_score, precision_score, recall_score\n",
        ")\n",
        "\n",
        "def evaluate(model, graph, dataset, device):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        all_nids = torch.arange(graph.num_nodes('user')).to(device)\n",
        "        z = model.get_embeddings(graph.to(device), all_nids)\n",
        "\n",
        "    preds = []\n",
        "    trues = []\n",
        "\n",
        "    for (pair, label) in dataset:\n",
        "        u, v = pair\n",
        "        u = torch.tensor([u], device=device)\n",
        "        v = torch.tensor([v], device=device)\n",
        "        label = torch.tensor([label], device=device)\n",
        "\n",
        "        score = model.predict(z, u, v)\n",
        "        pred = torch.sigmoid(score).item()\n",
        "\n",
        "        preds.append(pred)\n",
        "        trues.append(label.item())\n",
        "\n",
        "    preds_bin = [1 if p >= 0.5 else 0 for p in preds]\n",
        "\n",
        "    auc = roc_auc_score(trues, preds)\n",
        "    binary_f1 = f1_score(trues, preds_bin)\n",
        "    micro_f1 = f1_score(trues, preds_bin, average='micro')\n",
        "    macro_f1 = f1_score(trues, preds_bin, average='macro')\n",
        "    precision = precision_score(trues, preds_bin)\n",
        "    recall = recall_score(trues, preds_bin)\n",
        "\n",
        "    print(f\"\\n🎯 Evaluation Results:\")\n",
        "    print(f\"Micro-F1:   {micro_f1:.4f}\")\n",
        "    print(f\"Binary-F1:  {binary_f1:.4f}\")\n",
        "    print(f\"Macro-F1:   {macro_f1:.4f}\")\n",
        "    print(f\"AUC:        {auc:.4f}\")\n",
        "    print(f\"Precision:  {precision:.4f}\")\n",
        "    print(f\"Recall:     {recall:.4f}\")\n"
      ],
      "metadata": {
        "id": "ePBsqfvE0NkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, graph, label_dataset, device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPkbvtUH0Rzs",
        "outputId": "ad355c76-f9ff-4ea9-e717-5f63524e170e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 Evaluation Results:\n",
            "Micro-F1:   0.9528\n",
            "Binary-F1:  0.9751\n",
            "Macro-F1:   0.7653\n",
            "AUC:        0.9593\n",
            "Precision:  0.9645\n",
            "Recall:     0.9860\n"
          ]
        }
      ]
    }
  ]
}